---
layout: post
title: "Compute Signal Detection Theory Indices with R"
author: Dominique Makowski
author_web: https://dominiquemakowski.github.io/
date: 2018-03-29
summary: Compute Signal Detection Theory Indices (dprime, beta...) with R
---


Signal Detection Theory Indices (dprime, beta...)
-------------------------------------------------

Signal detection theory (SDT) is used when psychologists want to measure the way we make decisions under conditions of uncertainty. SDT assumes that the decision maker is not a passive receiver of information, but an active decision-maker who makes difficult perceptual judgments under conditions of uncertainty. To apply signal detection theory to a data set where stimuli were either present or absent, and the observer categorized each trial as having the stimulus present or absent, the trials are sorted into one of four categories: **Hit**, **Miss**, **Correct Rejection** and **False Alarm**.

![*Anderson (2015)*](https://www.frontiersin.org/files/Articles/147101/fpsyg-06-00762-HTML/image_m/fpsyg-06-00762-g001.jpg)

Based on the proportions of these types of trials, we can compute indices of sensitivity and response bias:

-   **d'** (*d prime*): The sensitivity. Reflects the distance between the two distributions: signal, and signal+noise and corresponds to the Z value of the hit-rate minus that of the false-alarm rate.
-   **beta**: The bias (criterion). The value for beta is the ratio of the normal density functions at the criterion of the Z values used in the computation of d'. This reflects an observer's bias to say 'yes' or 'no' with the unbiased observer having a value around 1.0. As the bias to say 'yes' increases (liberal), resulting in a higher hit-rate and false-alarm-rate, beta approaches 0.0. As the bias to say 'no' increases (conservative), resulting in a lower hit-rate and false-alarm rate, beta increases over 1.0 on an open-ended scale.
-   **A'** (*aprime*): Non-parametric estimate of discriminability. An A' near 1.0 indicates good discriminability, while a value near 0.5 means chance performance.
-   **B''D** (*b prime prime d*): Non-parametric estimate of bias. A B''D equal to 0.0 indicates no bias, positive numbers represent conservative bias (*i.e.*, a tendency to answer 'no'), negative numbers represent liberal bias (i.e. a tendency to answer 'yes'). The maximum absolute value is 1.0.
-   **c**: Another index of bias. the number of standard deviations from the midpoint between these two distributions, *i.e.*, a measure on a continuum from "conservative" to "liberal".

To compute them with `psycho`, simply run the following:

``` r
library(psycho)

# Let's simulate three participants with different results at a perceptual detection task
df <- data.frame(Participant = c("A", "B", "C"),
                 n_hit = c(1, 2, 5),
                 n_fa = c(1, 3, 5), 
                 n_miss = c(6, 8, 1),
                 n_cr = c(4, 8, 9))

indices <- psycho::dprime(df$n_hit, df$n_fa, df$n_miss, df$n_cr)
df <- cbind(df, indices)
```

| Participant |  n\_hit|  n\_fa|  n\_miss|  n\_cr|      dprime|       beta|     aprime|        bppd|           c|
|:------------|-------:|------:|--------:|------:|-----------:|----------:|----------:|-----------:|-----------:|
| A           |       1|      1|        6|      4|  -0.1925836|  0.8518485|  0.5000000|   0.9459459|   0.8326077|
| B           |       2|      3|        8|      8|  -0.1981923|  0.8735807|  0.4106061|   0.8285714|   0.6819377|
| C           |       5|      5|        1|      9|   0.9952151|  0.8827453|  0.5000000|  -0.9230769|  -0.1253182|



Credits
=======

This package helped you? You can cite [`psycho`](https://github.com/neuropsychology/psycho.R) as follows:

-   Makowski, (2018). *The psycho Package: an Efficient and Publishing-Oriented Workflow for Psychological Science*. Journal of Open Source Software, 3(22), 470. <https://doi.org/10.21105/joss.00470>

Previous blogposts
==================

-   [Copy/paste t-tests Directly to Manuscripts](https://neuropsychology.github.io/psycho.R/2018/06/19/analyze_ttest.html)
-   [APA Formatted Bayesian Correlation](https://neuropsychology.github.io/psycho.R/2018/06/11/bayesian_correlation.html)
-   [Fancy Plot (with Posterior Samples) for Bayesian Regressions](https://neuropsychology.github.io/psycho.R/2018/06/03/plot_bayesian_model.html)
-   [How Many Factors to Retain in Factor Analysis](https://neuropsychology.github.io/psycho.R/2018/05/24/n_factors.html)
-   [Beautiful and Powerful Correlation Tables](https://neuropsychology.github.io/psycho.R/2018/05/20/correlation.html)
-   [Format and Interpret Linear Mixed Models](https://neuropsychology.github.io/psycho.R/2018/05/10/interpret_mixed_models.html)
-   [How to do Repeated Measures ANOVAs](https://neuropsychology.github.io/psycho.R/2018/05/01/repeated_measure_anovas.html)
-   [Standardize (Z-score) a dataframe](https://neuropsychology.github.io/psycho.R/2018/03/29/standardize.html)
-   [Compute Signal Detection Theory Indices](https://neuropsychology.github.io/psycho.R/2018/03/29/SDT.html)
